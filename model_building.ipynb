{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2++3L1wlS9M+nkGxz7vMB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazueuglena/mimosa_img_process/blob/main/model_building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNyrqvXkTv8A"
      },
      "outputs": [],
      "source": [
        "# モデル構築のためのプログラム\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install ipython-autotime\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications.xception import Xception\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.pooling import GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "times = 0\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "while times <= 180:\n",
        "    # 入力フォルダと出力フォルダのパス\n",
        "    folder_path = \"/content/drive/MyDrive/cut_mimosa/mimosa_output\"\n",
        "    folder_path = os.path.join(folder_path, str(times))\n",
        "\n",
        "    # フォルダが存在しない場合は処理をスキップ\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"フォルダ {folder_path} が存在しません。処理をスキップします。\")\n",
        "        times += 20\n",
        "        continue\n",
        "\n",
        "    # フォルダ内のファイルを取得\n",
        "    file_list = os.listdir(folder_path)\n",
        "    if file_list:\n",
        "        for file in file_list:\n",
        "            image = Image.open(os.path.join(folder_path, file))\n",
        "            # RGB変換\n",
        "            image = image.convert('RGB')\n",
        "            new_size = (350, 585)  # 新しいサイズ (幅, 高さ)\n",
        "            image = image.resize(new_size)\n",
        "            # 画像から配列に変換\n",
        "            # 葉の開き具合を写真の名前の最初に入れ、〜-の形で元の名前と区切る\n",
        "            data = np.asarray(image)\n",
        "            file_split = [i for i in file.split('_')]\n",
        "            # XにNumPy配列形式の画像を追加\n",
        "            X.append(data)\n",
        "            # Yに開き具合を代入\n",
        "            Y.append(float(file_split[0]))\n",
        "\n",
        "    times += 20\n",
        "\n",
        "# NumPy配列に変換\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "print(X.shape, Y.shape)\n",
        "\n",
        "\n",
        "\n",
        "# trainデータとtestデータに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    Y,\n",
        "    random_state = 0,\n",
        "    test_size = 0.2\n",
        ")\n",
        "\n",
        "del X,Y\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "# データ型の変換＆正規化　判定の精度を上げるため\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# trainデータからvalidデータを分割\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    random_state = 0,\n",
        "    test_size = 0.2\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)\n",
        "\n",
        "\n",
        "#ここからCNNの構築開始　モデルEceptionを読み込み　全層結合を削除　input_shapeの値はうまく行かなかったらNoneに\n",
        "#下に画像のピクセルのサイズを入れないとエラーが起きる\n",
        "height = 585\n",
        "width = 350\n",
        "\n",
        "base_model = Xception(\n",
        "    include_top = False,\n",
        "    weights = \"imagenet\",\n",
        "    input_shape = (height, width, 3)\n",
        ")\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1)(x)\n",
        "\n",
        "#画像データの少なさを補うためのプログラム\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center = False,\n",
        "    samplewise_center = False,\n",
        "    featurewise_std_normalization = False,\n",
        "    samplewise_std_normalization = False,\n",
        "    zca_whitening = False,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True\n",
        ")\n",
        "\n",
        "#学習の進捗状況の監視\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor = 'val_loss',\n",
        "    patience = 10,\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "# ModelCheckpoint\n",
        "weights_dir = '/content/drive/My Drive/weights/'\n",
        "if os.path.exists(weights_dir) == False:os.mkdir(weights_dir)\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    weights_dir + \"val_loss{val_loss:.3f}.hdf5\",\n",
        "    monitor = 'val_loss',\n",
        "    verbose = 1,\n",
        "    save_best_only = True,\n",
        "    #モデルのアーキテクチャと設定を下のプログラムで削除しちゃってるので、うまく行かなかったら＝Falseに変えてみる\n",
        "    save_weights_only = True,\n",
        "    period = 3\n",
        ")\n",
        "\n",
        "# reduce learning rate\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor = 'val_loss',\n",
        "    #factor の値はモデルに応じて変更　初期値は0.1\n",
        "    factor = 0.1,\n",
        "    patience = 3,\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "logging = TensorBoard(log_dir = \"/content/drive/My Drive/log/\")\n",
        "\n",
        "# 損失関数　RMSEを定義　他にもMSEなどでもいいかも　うまく行かなかったら変更\n",
        "from keras import backend as K\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis = -1))\n",
        "\n",
        "# ネットワーク定義\n",
        "model = Model(inputs = base_model.input, outputs = predictions)\n",
        "\n",
        "#108層までは固定　エッジングなどの基本的なことをする\n",
        "for layer in model.layers[:108]:\n",
        "    layer.trainable = False\n",
        "\n",
        "    # Batch Normalizationのfreeze解除\n",
        "    if layer.name.startswith('batch_normalization'):\n",
        "        layer.trainable = True\n",
        "    if layer.name.endswith('bn'):\n",
        "        layer.trainable = True\n",
        "\n",
        "#109層以降、学習させる　オジギソウの画像に合わせて\n",
        "for layer in model.layers[108:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# layer.trainableの設定後にcompile\n",
        "model.compile(\n",
        "    optimizer = Adam(),\n",
        "    loss = root_mean_squared_error,\n",
        ")\n",
        "\n",
        "%load_ext autotime\n",
        "hist = model.fit_generator(\n",
        "    #batch_sizeとは一度にCNNに入れるデータの量 (64,128でできるならそっちのほうが精度が高い)　すべてやってみて一番いいやつを使用\n",
        "    datagen.flow(X_train, y_train, batch_size = 32),\n",
        "    steps_per_epoch = X_train.shape[0] // 32,\n",
        "    epochs = 50,\n",
        "    validation_data = (X_valid, y_valid),\n",
        "    callbacks = [early_stopping, reduce_lr],\n",
        "    shuffle = True,\n",
        "    verbose = 1\n",
        ")\n"
      ]
    }
  ]
}